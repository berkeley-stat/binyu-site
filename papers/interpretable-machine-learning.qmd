---
title: "Interpretable Machine Learning"
---

[Complete Paper List in Reverse Chronological Order](../papers.qmd)

## Selected Recent Papers on Interpretable Machine Learning

1. A. R. Hsu, Y. Cherapanamjeri, A. Y. Odisho, P. R. Carroll, B. Yu (2024). [Mechanistic Interpretation through Contexual Decomposition in Transformers.](https://arxiv.org/pdf/2407.00886) [https://arxiv.org/pdf/2407.00886](https://arxiv.org/pdf/2407.00886).
1. Y. Chen, C. Singh, X. Liu, S. Zuo, B. Yu, H. He, J. Gao (2024). [Towards consistent natural-language explanations via explanation-consistent finetuning.](https://arxiv.org/abs/2401.13986) [https://arxiv.org/abs/2401.13986](https://arxiv.org/abs/2401.13986)
1. Q. Zhang, C. Singh, L. Liu, X. Liu, B. Yu, J. Gao, T. Zhao (2023). [Tell your model where to attend: post-hoc attention steering for LLMs.](https://arxiv.org/abs/2311.02262) ICLR 2024. https://arxiv.org/abs/2311.02262
1. A. Agarwal, A. M. Kenny, Y. S. Tan, T. M. Tang, B. Yu (2023). MDI+: a flexible random forest-based feature importance framework. [https://arxiv.org/abs/2307.01932](https://arxiv.org/abs/2307.01932) (PCS related)
1. A. R. Hsu, Y. Cherapanamjeri, B. Park, T. Naumann, A. Odisho, and B. Yu (2023). [Diagnosing transformers: illuminating feature space for clinical decison-making.](https://arxiv.org/abs/2305.17588) ICLR (2024) [https://arxiv.org/abs/2305.17588](https://arxiv.org/abs/2305.17588)
1. C. Singh, A. R. Hsu, R. Antonello, S. Jain, A. G. Huth, B. Yu and J. Gao (2023). [Explaining black box text modules in natural language with language models.](https://arxiv.org/abs/2305.09863)
1. C. Singh, W. Ha and B. Yu (2021). [Interpreting and Improving Deep-Learning Models with Reality Checks](https://arxiv.org/abs/2108.06847). [https://arxiv.org/abs/2108.06847](https://arxiv.org/abs/2108.06847) to appear in the book entitled "xxAI - Beyond Explainable AI" (eds. Andreas Holzinger, Randy Goebel, Ruth Fong, Taesup Moon, Klaus-Robert MÃ¼ller, and Wojciech Samek).
1. W. Ha, C. Singh, F. Lanusse, S. Upadhyayula, and B. Yu (2021). [Adaptive Wavelet Distillation from Neural Networks through Interpretation.](https://nips.cc/Conferences/2021/ScheduleMultitrack?event=28027) Proc. NeurIPS 2021. ([code](https://github.com/Yu-Group/adaptive-wavelets))
1. L. Reiger, J. W. Murdoch, S. Singh, B. Yu (2020). [Interpretations are Useful: Penalizing Explanations to Align Neural Networks with Prior Knowledge](https://proceedings.icml.cc/static/paper_files/icml/2020/992-Paper.pdf). ICML Proceedings. ([code](https://github.com/laura-rieger/deep-explanation-penalization))
1. C. Singh, W. Ha, F. Lanusse, V. Boehm , J. Liu, B. Yu (2020). [Transformation Importance with Applications to Cosmology](https://arxiv.org/pdf/2003.01926.pdf) ICLR Workshop paper. ([code](https://github.com/csinva/transformation-importance))
1. W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, and B. Yu* (2019) [Definitions, methods, and applications in interpretable machine learning.](https://www.stat.berkeley.edu/~binyu/ps/papers2020/iML19-Murdochetal.pdf) PNAS, 116 (44) 22071-22080.
1. W. J. Murdoch, C. Sign, and B. Yu (2019). [Hierarchical interpretations for neural network predictions.](https://openreview.net/pdf?id=SkEqro0ctQ) ICLR. ([code](https://github.com/csinva/hierarchical-dnn-interpretations))
1. J. Murdoch, P. Liu, and B. Yu (2018) [Beyond word importance: contextual decomposition to extract interactions from LSTMs.](https://arxiv.org/abs/1801.05453) Proc. ICLR 2018. [https://arxiv.org/abs/1705.07356](https://arxiv.org/abs/1705.07356) ([code](https://github.com/csinva/hierarchical-dnn-interpretations))
