---
title: Biography
---

# Biography

<img src="images/bio1.jpg" alt="Bin Yu speaking" style="float:right; margin:0 0 1em 2em; width:200px; border-radius:8px;" />

Bin Yu is CDSS Chancellor's Distinguished Professor in the Departments of statistics and EECS, and Center for Computational Biology, and serves as a scientific advisor at the Simons Institute for the Theory of Computing, all at UC Berkeley.

She obtained her BS Degree in Mathematics from Peking University, and MS and PhD Degrees in Statistics from UC Berkeley. She was Assistant Professor at UW-Madison, Visiting Assistant Professor at Yale University, Member of Technical Staff at Lucent Bell-Labs, and Miller Research Professor at Berkeley. She was a Visiting Faculty at MIT, ETH, Poincare Institute, Peking University, INRIA-Paris, Fields Institute at University of Toronto, Newton Institute at Cambridge University, and the Flatiron Institute in NYC. She was Chair of the Department of Statistics at UC Berkeley from 2009 to 2012. Recently, she was a 50% consultant researcher in the deep learning group of MSR at Redmond (2022-2023).

She is a Member of the U.S. National Academy of Sciences and of the American Academy of Arts and Sciences. She was President of the Institute of Mathematical Statistics (IMS), Guggenheim Fellow, Tukey Memorial Lecturer of the Bernoulli Society, Rietz Lecturer of IMS, and a COPSS E. L. Scott Prize winner. Recently, she delivered the Wald Memorial Lectures of IMS and COPSS Distinguished Achievement Award and Lecture (DAAL) (formerly Fisher Award and Lecture) at JSM in 2023. She served on the Inaugural Scientific Committee of the UK Turing Institute for Data Science and AI. She holds an Honorary Doctorate from the University of Lausanne in Switzerland. She is serving on the Editorial Board of Proceedings of National Academy of Sciences (PNAS).

She has published more than 170 papers in premier venues on statistical machine learning including deep learning and the Predictability-Computability-Stability (PCS) framework and documentation for [veridical (truthful) data science](https://vdsbook.com/) and these papers not only investigate a wide range of research topics from practice to algorithms and to theory, but also seek deep insights. The breadth and depth of her research experience enabled unique and novel solutions to interdisciplinary data problems in audio and image compression, network tomography, remote sensing, climate science, neuroscience, genomics, and precision medicine.

Currently, she is championing "in-context" research with experts in the subject knowledge and leading research in interpretable machine learning (e.g. tree-based methods and deep learning) and causal inference to design algorithms such as [iterative random forests (iRF)](https://www.pnas.org/doi/10.1073/pnas.1711236115), [Efficient Automated Circuit Discovery in Transformers using Contextual Decomposition (CD-T)](https://openreview.net/forum?id=41HlN8XYM5) and [adaptive wavelet distillation (AWD)](https://proceedings.neurips.cc/paper/2021/file/acaa23f71f963e96c8847585e71352d6-Paper.pdf) for interpreting deep neural networks and [X-learner for heterogeneous treatment effect estimation in causal inference](https://www.pnas.org/doi/10.1073/pnas.1804597116). Recently, she and her collaborators developed PCS-guided [low-signal signed iterative random forests (lo-siRF)](https://www.medrxiv.org/content/10.1101/2023.11.06.23297858v2) that recommends genetic targets for high-yield follow-up experiments with a case study showing epistasis regulation controls cardiac hypertrophy through gene-silencing experiment (4 out of 5 sets of experiments found causal genes or gene-gene interactions). She is also working on relevant deep learning theory and practical algorithms with her team (e.g. the development of [LoRA+ algorithm](https://github.com/nikhil-ghosh-berkeley/loraplus) for fine-tuning large language models).

Previously, she pioneered Vapnik-Chervonenkis (VC) type theory needed for asymptotic analysis of time series and spatio-temporal processes, and made fundamental contributions to information theory and statistics through work on minimum description length (MDL) and entropy estimation, and through theory on sparse modeling, boosting and spectral clustering, EM algorithm, and MCMC convergence analysis. With her students and collaborators, she developed a highly cited spatially adaptive wavelet image denoising method and a low-complexity low-delay perceptually lossless audio coder that was incorporated in Bose wireless speakers, and developed a fast and well-validated Arctic cloud detection algorithm using NASA's MISR data. With the Jack Gallant Lab and her students, she developed predictive models of fMRI brain activity in vision neuroscience that made "mind-reading" possible (or reconstruction of movies using only fMRI signals).

Moreover, she served on editorial boards including Annals of Statistics, Journal of American Statistical Association, and Journal of Machine Learning Research. Her leadership roles included co-chairing the National Scientific Committee of the Statistical and Applied Mathematical Sciences Institute (SAMSI), and serving on the scientific advisory committee of SAMSI and IPAM, and on the board of trustees of ICERM and the Board of Governors of IEEE-IT Society. She recently served on the scientific advisory committee for the IAS Special Year on optimization, statistics and theoretical machine learning, the Scientific Advisory Boards of Canadian Statistical Sciences Institute (CANSSI). She is serving on the advisory board of the AI Policy Hub at UC Berkeley, the Scientific Advisory Committee of the Department of Quantitative and Computational Biology at USC, and on the External Advisory Committee, Learning the Earth with Artificial Intelligence and Physics (LEAP), an NSF Science and Technology Center (STC), at Columbia University.
