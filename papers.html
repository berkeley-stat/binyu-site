<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Papers – Bin Yu</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-97b0f3e763d66a0e8f9e9a9f159311c2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://siteimproveanalytics.com/js/siteanalyze_6294756.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Bin Yu</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./people.html"> 
<span class="menu-text">People</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./papers.html" aria-current="page"> 
<span class="menu-text">Papers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./books.html"> 
<span class="menu-text">Books</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./teaching.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#papers" id="toc-papers" class="nav-link active" data-scroll-target="#papers">Papers</a>
  <ul class="collapse">
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section">2024</a></li>
  <li><a href="#section-1" id="toc-section-1" class="nav-link" data-scroll-target="#section-1">2023</a></li>
  <li><a href="#section-2" id="toc-section-2" class="nav-link" data-scroll-target="#section-2">2022</a></li>
  <li><a href="#section-3" id="toc-section-3" class="nav-link" data-scroll-target="#section-3">2021</a></li>
  <li><a href="#section-4" id="toc-section-4" class="nav-link" data-scroll-target="#section-4">2020</a></li>
  <li><a href="#section-5" id="toc-section-5" class="nav-link" data-scroll-target="#section-5">2019</a></li>
  <li><a href="#section-6" id="toc-section-6" class="nav-link" data-scroll-target="#section-6">2018</a></li>
  <li><a href="#section-7" id="toc-section-7" class="nav-link" data-scroll-target="#section-7">2017</a></li>
  <li><a href="#section-8" id="toc-section-8" class="nav-link" data-scroll-target="#section-8">2016</a></li>
  <li><a href="#section-9" id="toc-section-9" class="nav-link" data-scroll-target="#section-9">2015</a></li>
  <li><a href="#section-10" id="toc-section-10" class="nav-link" data-scroll-target="#section-10">2014</a></li>
  <li><a href="#section-11" id="toc-section-11" class="nav-link" data-scroll-target="#section-11">2013</a></li>
  <li><a href="#section-12" id="toc-section-12" class="nav-link" data-scroll-target="#section-12">2012</a></li>
  <li><a href="#section-13" id="toc-section-13" class="nav-link" data-scroll-target="#section-13">2011</a></li>
  <li><a href="#section-14" id="toc-section-14" class="nav-link" data-scroll-target="#section-14">2010</a></li>
  <li><a href="#section-15" id="toc-section-15" class="nav-link" data-scroll-target="#section-15">2009</a></li>
  <li><a href="#section-16" id="toc-section-16" class="nav-link" data-scroll-target="#section-16">2008</a></li>
  <li><a href="#section-17" id="toc-section-17" class="nav-link" data-scroll-target="#section-17">2007</a></li>
  <li><a href="#section-18" id="toc-section-18" class="nav-link" data-scroll-target="#section-18">2006</a></li>
  <li><a href="#section-19" id="toc-section-19" class="nav-link" data-scroll-target="#section-19">2005</a></li>
  <li><a href="#section-20" id="toc-section-20" class="nav-link" data-scroll-target="#section-20">2004</a></li>
  <li><a href="#section-21" id="toc-section-21" class="nav-link" data-scroll-target="#section-21">2003</a></li>
  <li><a href="#section-22" id="toc-section-22" class="nav-link" data-scroll-target="#section-22">2002</a></li>
  <li><a href="#section-23" id="toc-section-23" class="nav-link" data-scroll-target="#section-23">2001</a></li>
  <li><a href="#section-24" id="toc-section-24" class="nav-link" data-scroll-target="#section-24">2000</a></li>
  <li><a href="#section-25" id="toc-section-25" class="nav-link" data-scroll-target="#section-25">1999</a></li>
  <li><a href="#section-26" id="toc-section-26" class="nav-link" data-scroll-target="#section-26">1998</a></li>
  <li><a href="#section-27" id="toc-section-27" class="nav-link" data-scroll-target="#section-27">1997</a></li>
  <li><a href="#section-28" id="toc-section-28" class="nav-link" data-scroll-target="#section-28">1996</a></li>
  <li><a href="#section-29" id="toc-section-29" class="nav-link" data-scroll-target="#section-29">1995</a></li>
  <li><a href="#section-30" id="toc-section-30" class="nav-link" data-scroll-target="#section-30">1994</a></li>
  <li><a href="#section-31" id="toc-section-31" class="nav-link" data-scroll-target="#section-31">1993</a></li>
  <li><a href="#section-32" id="toc-section-32" class="nav-link" data-scroll-target="#section-32">1992</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Papers</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="papers" class="level1">
<h1>Papers</h1>
<p><em>For the most up-to-date and complete list, see <a href="https://scholar.google.com/citations?user=xT19Jc0AAAAJ&amp;hl=en">Google Scholar</a> or <a href="https://arxiv.org/search/?query=bin+yu&amp;searchtype=author">arXiv</a>.</em></p>
<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section">2024</h2>
<p>A. R. Hsu, Y. Cherapanamjeri, A. Y. Odisho, P. R. Carroll, B. Yu (2024). Mechanistic Interpretation through Contextual Decomposition in Transformers. (<a href="https://arxiv.org/pdf/2407.00886">paper</a>)</p>
<p>Y. S. Tan, O. Ronen, T. Saarinen, B. Yu (2024). The Computational Curse of Big Data for Bayesian Additive Regression Trees: a Hitting Time Analysis. (<a href="https://arxiv.org/pdf/2406.19958">paper</a>)</p>
<p>O. Ronen, A. I. Humayun, R. Balestriero, R. Baraniuk, B. Yu (2024). ScaLES: Scalable Latent Exploration Score for Pre-Trained Generative Networks. (<a href="https://arxiv.org/pdf/2406.09657">paper</a>)</p>
<p>S. Hayou, N. Ghosh, B. Yu (2024). The Impact of Initialization on LoRA Fineuning Dynamics. (<a href="https://arxiv.org/pdf/2406.08447">paper</a>)</p>
<p>B. Yu (2024). After Computational Reproducibility: Scientific Reproducibility and Trustworthy AI. (Harvard Data Science Review) (<a href="https://hdsr.mitpress.mit.edu/pub/8qexde24/release/1">paper</a>)</p>
<p>S. Hayou, N. Ghosh, B. Yu (2024). LoRA+: Efficient Low Rank Adaptation of Large Models. (Proc. ICML) (<a href="https://arxiv.org/abs/2402.12354">paper</a>)</p>
<p>C. F. Elliott, J. Duncan, T. M. Tang, M. Behr, K. Kumbier, B. Yu (2024). Designing a data science simulation with MERITS: a primer. (<a href="https://arxiv.org/abs/2403.08971">paper</a>)</p>
<p>Y. Chen, C. Singh, X. Liu, S. Zuo, B. Yu, H. He, J. Gao (2024). Towards consistent natural-language explanations via explanation-consistent finetuning. (<a href="https://arxiv.org/abs/2401.13986">paper</a>)</p>
<p>N. R. Mallinar, A. Zane, S. Frei, B. Yu (2024). Minimum-Norm Interpolation Under Covariate Shift. (Proc. ICML) (<a href="https://arxiv.org/pdf/2404.00522">paper</a>)</p>
<p>L. Sun, A. Agarwal, A. Kornblith, B. Yu, C. Xiong (2024). ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance. (Proc. ICML) (<a href="https://arxiv.org/abs/2402.13448">paper</a>)</p>
</section>
<section id="section-1" class="level2">
<h2 class="anchored" data-anchor-id="section-1">2023</h2>
<p>C. Singh<em>, A. R. Hsu</em>, R. Antonello, S. Jain, A. G. Huth, B. Yu, J. Gao (2023). Explaining black box text modules in natural language with language models. (<a href="https://arxiv.org/abs/2305.09863">paper</a>)</p>
<p>Q. Zhang, C. Singh, L. Liu, X. Liu, B. Yu, J. Gao, T. Zhao (2023). Tell your model where to attend: post-hoc attention steering for LLMs. (<a href="https://arxiv.org/abs/2311.02262">paper</a>)</p>
<p>Q. Wang<em>, T. M. Tang</em>, N. Youlton, C. S. Weldy, A. M. Kenney, O. Ronen, J. W. Hughes, E. T. Chin, S. C. Sutton, A. Agarwal, X. Li, M. Behr, K. Kumbier, C. S. Moravec, W. H. W. Tang, K. B. Margulies, T. P. Cappola, A. J. Buitte, R. Arnaout, J. B. Brown, J. R. Priest, V. N. Parikh, B. Yu<em>, E. Ashley</em> (2023). Epistasis regulates genetic control of cardiac hypertrophy. (<a href="https://www.medrxiv.org/content/10.1101/2023.11.06.23297858v1">paper</a>) (<a href="https://github.com/Yu-Group/epistasis-cardiac-hypertrophy">code</a>) (<a href="https://yu-group.github.io/epistasis-cardiac-hypertrophy/#overview">PCS documentation</a>)</p>
<p>R. Cahill, Y. Wang, R. P. Xian, A. J. Lee, H. Zeng, B. Yu, B. Tasic, R. Abbasi-Asl (2023). Unsupervised pattern discovery in spatial gene expression atlas reveals mouse brain regions beyond established ontology. (<a href="https://www.biorxiv.org/content/10.1101/2023.03.10.531984v2">paper</a>) (<a href="https://github.com/abbasilab/osNMF">code</a>)</p>
<p>E. Irajizad, A. Kenney, T. Tang, J. Vykoukal, R. Wu, E. Murage, J. B. Dennison, M. Sans, J. P. Long, M. Loftus, J. A. Chabot, M. D. Kluger, F. Kastrinos, L. Brais, A. Babic, K. Jajoo, L. S. Lee, T. E. Clancy, K. Ng, A. Bullock, J. M. Genkinger, A. Maitra, K. A. Do, B. Yu, B. W. Wolpin, S. Hanash, J. F. Fahrmann. (2023). A blood-based metabolomic signature predictive of risk for pancreatic cancer. Cell Reports Medicine 4(9): 101194. doi: 10.1016/j.xcrm.2023.101194. (PCS related) (<a href="https://pubmed.ncbi.nlm.nih.gov/37729870/">paper</a>) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10518497/">Editorial</a>)</p>
<p>R. Dwivedi, C. Singh, B. Yu, M. Wainwright (2023). Revisiting miniumu description length complexity in overparametrized models. JMLR, 24(268): 1-59. (<a href="https://jmlr.org/papers/v24/21-1133.html">paper</a>)</p>
<p>K. Wu, Y. Chen, W. Ha, B. Yu (2023). Prominent roles of conditionally invariant components in domain adaptation: theory and algorithms. JMLR (accepted). (<a href="https://arxiv.org/abs/2309.10301">paper</a>)</p>
<p>N. Ghosh, S. Frei, W. Ha, B. Yu (2023). The effect of SGD batch size on autoencoder learning: sparsity, sharpness and feature learning. (<a href="https://arxiv.org/abs/2308.03215">paper</a>)</p>
<p>R. Netzorg, J. Li, B. Yu (2024). Improving prototypical part networks with reward reweighting, reselection, and retraining. Proc. ICML. (<a href="https://arxiv.org/abs/2307.03887">paper</a>)</p>
<p>A. Agarwal, A. M. Kenny, Y. S. Tan, T. M. Tang, B. Yu (2023). MDI+: a flexible random forest-based feature importance framework. (PCS related) (<a href="https://arxiv.org/abs/2307.01932">paper</a>)</p>
<p>A. R. Hsu, Y. Cherapanamjeri, B. Park, T. Naumann, A. Odisho, and B. Yu (2023). Diagnosing transformers: illuminating feature space for clinical decison-making. Proc. ICLR. (<a href="https://arxiv.org/abs/2305.17588">paper</a>)</p>
<p>C. Singh, A. R. Hsu, R. Antonello, S. Jain, A. G. Huth, B. Yu and J. Gao (2023). Explaining black box text modules in natural language with language models. (<a href="https://arxiv.org/abs/2305.09863">paper</a>)</p>
</section>
<section id="section-2" class="level2">
<h2 class="anchored" data-anchor-id="section-2">2022</h2>
<p>D. Shen, P. Ding, J. Sekhon, B. Yu (2022). Same root different leaves: time series and cross-sectional methods in panel data. Econometrica (accepted). (<a href="https://arxiv.org/abs/2207.14481">paper</a>)</p>
<p>B. Park, X. Wu, B. Yu, A. Zhou (2022). Offline evaluation in RL: soft stability weighting to combine fitted Q-learning and model-based methods. NeurIPS 3rd Offline Reinforcement Learning Workshop. (<a href="https://openreview.net/forum?id=R3h3-bt0mq">paper</a>)</p>
<p>Y. S. Tan, C. Singh, K. Nasseri, A. Agarwal, J. Duncan, O. Ronen, M. Epland, A. Kornblith, B. Yu (2022). Fast interpretable greedy-tree sums (FIGS). (<a href="https://arxiv.org/abs/2201.11931">paper</a>) (<a href="https://github.com/csinva/imodels">code</a>)</p>
<p>A. Agarwal, Y. S. Tan, O. Ronen, C. Singh, B. Yu (2022). Hierarchical shrinkage: improving accuracy and interpretability of tree-based methods. Proc. ICML (<a href="https://arxiv.org/abs/2202.00858">paper</a>) (<a href="https://github.com/csinva/imodels">code</a>).</p>
<p>B. Yu and C. Singh (2022). Seven principles for rapid-response data science: lessons learned from covid-19 forecasting. Statistical Science, 36(2):266-269. (<a href="https://projecteuclid.org/journals/statistical-science/volume-37/issue-2/Seven-Principles-for-Rapid-Response-Data-Science--Lessons-Learned/10.1214/22-STS855.full">paper</a>)</p>
<p>N. Ghosh, S. Mei, and B. Yu (2022). The three stages of dynamics in high-dimensional kernel methods. Proc. ICLR, 2022. (<a href="https://arxiv.org/abs/2111.07167">paper</a>)</p>
</section>
<section id="section-3" class="level2">
<h2 class="anchored" data-anchor-id="section-3">2021</h2>
<p>Y. Tan, A. Agarwal, and B. Yu (2021). A cautionary tale on fitting decision trees to data from additive models: generalization lower bounds. Proc. AISTATS. (<a href="https://arxiv.org/abs/2110.09626">paper</a>)</p>
<p>N. Altieri, B. Park, J. DeNero, A. Odisho, B. Yu. (2021). Improving natural language information extraction from cancer pathology reports using transfer learning and zero-shot string similarity. JAMIA Open. 2021 Sept.&nbsp;30 4(3). (<a href="https://pubmed.ncbi.nlm.nih.gov/34604711/">paper</a>)</p>
<p>C. Singh, W. Ha and B. Yu (2021). Interpreting and Improving Deep-Learning Models with Reality Checks. To appear in “xxAI - Beyond Explainable AI” (eds.&nbsp;Holzinger et al.). (<a href="https://arxiv.org/abs/2108.06847">paper</a>)</p>
<p>W. Ha, C. Singh, F. Lanusse, S. Upadhyayula, and B. Yu (2021). Adaptive Wavelet Distillation from Neural Networks through Interpretation. Proc. NeurIPS 2021. (<a href="https://nips.cc/Conferences/2021/ScheduleMultitrack?event=28027">paper</a>) (<a href="https://github.com/Yu-Group/adaptive-wavelets">code</a>)</p>
<p>M. Behr, Y. Wang, X. Li, B. Yu (2022). Provable Boolean Interaction Recovery from Tree Ensemble obtained via Random Forests. PNAS. (PCS-related) (<a href="https://arxiv.org/abs/2102.11800">paper</a>) (<a href="https://www.pnas.org/doi/10.1073/pnas.1711236115">theory for iRF</a>)</p>
<p>N. Altieri, B. Park, M. Olson, J. DeNero, A. Odisho, B. Yu. (2021). Supervised line attention for tumor attribute classification from pathology reports: Higher performance with less data. Journal of Biomedical Informatics. 122 (2021) 103872. (<a href="https://arxiv.org/abs/2012.08113">paper</a>)</p>
</section>
<section id="section-4" class="level2">
<h2 class="anchored" data-anchor-id="section-4">2020</h2>
<p>M. Behr<em>, K. Kumbier</em>, A. Cordova-Palomera, M. Aguirre, E. Ashley, A. Butte, R. Arnaout, J. B. Brown, J. Preist<em>, B. Yu</em> (2020). Learning epistatic polygenic phenotypes with Boolean interactions. (PCS inference case study) (<a href="https://www.biorxiv.org/content/10.1101/2020.11.24.396846v1">paper</a>) (<a href="https://github.com/merlebehr/epiTree">code</a>)</p>
<p>B. Norgeot<em>, G. Quer, B. K. Beaulieu-Jones, A. Torkamani, R. Dias, M. Gianfrancesco, R. Arnaout, I. S. Kohane, S. Saria, E. Topol, Z. Obermeyer, B. Yu &amp; A. Butte</em> (2020). Minimum information about clinical artificial intelligence modeling: the MI-CLAIM checklist, Nature Medicine, 26, 1320–1324. (<a href="https://www.nature.com/articles/s41591-020-1041-y">paper</a>)</p>
<p>B. Yu (2020). Stability expanded, in reality. Harvard Data Science Review (PCS related) (<a href="https://hdsr.mitpress.mit.edu/pub/ekrhsui8/release/1">paper</a>)</p>
<p>B. Yu and R. Barter (2020). Data science process: one culture. JASA. (PCS related) (<a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.2020.1762615?journalCode=uasa20">paper</a>)</p>
<p>R. Dwivedi, Y. Tan, B. Park, M. Wei, K. Horgan, D. Madigan, B. Yu (2020). Stable discovery of interpretable subgroups via calibration in causal studies (staDISC). International Statistical Review (PCS case study for causal inference) (<a href="https://onlinelibrary.wiley.com/doi/10.1111/insr.12427">paper</a>) (<a href="https://github.com/Yu-Group/stadisc">code</a>)</p>
<p>X. Li, T. M. Tang, X. Wang, J. A. Kocher, B. Yu (2020). A stability-driven protocol for drug response interpretable prediction (staDRIP). NeurISP workshop on ML4H (Machine learning for Health) Extended Abstract. (<a href="https://arxiv.org/abs/2011.06593">paper</a>)</p>
<p>A. Y. Odisho, B. Park, N. Altieri, J. DeNero, M. R Cooperberg, P. R .Carroll, B. Yu (2020). Natural language processing systems for pathology parsing in limited data environments with uncertainty estimation. JAMIA Open. (<a href="https://academic.oup.com/jamiaopen/article/3/3/431/5922788">paper</a>)</p>
<p>L. Reiger, J. W. Murdoch, S. Singh, B. Yu (2020). Interpretations are Useful: Penalizing Explanations to Align Neural Networks with Prior Knowledge. ICML Proceedings. (<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/992-Paper.pdf">paper</a>) (<a href="https://github.com/laura-rieger/deep-explanation-penalization">code</a>)</p>
<p>C. Singh, W. Ha, F. Lanusse, V. Boehm, J. Liu, B. Yu (2020). Transformation Importance with Applications to Cosmology. ICLR Workshop paper. (<a href="https://arxiv.org/pdf/2003.01926.pdf">paper</a>) (<a href="https://github.com/csinva/transformation-importance">code</a>)</p>
<p>N. Altieri, R. Barter, J. Duncan, R. Dwivedi, K. Kumbier, X. Li, R. Netzorg, B. Park, C. Singh<em>, Y. Tan, T.Tang, Y. Wang, C. Zhang, B. Yu</em>. (2020) Curating a COVID-19 data repository and forecasting county-level death counts in the United States. Harvard Data Science Review (<a href="https://hdsr.mitpress.mit.edu/pub/p6isyf0g/release/1">paper</a>) (<a href="https://github.com/Yu-Group/covid19-severity-prediction">code</a>) (<a href="https://covidseverity.com/">7-day prediction results</a>) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2020/RDSS20-yu.mp4">Short talk video</a>)</p>
<p>B. Yu and K. Kumbier (2020) Veridical data science (PCS framework), PNAS. 117 (8), 3920-3929. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2020/VDS20-YuKumbier.pdf">paper</a>) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2020/VDS20-QnAsBinYu.pdf">QnAs with Bin Yu</a>)</p>
<p>R. Dwivedi, N. Ho, K. Khamaru, M. J. Wainwright, M. I. Jordan and B. Yu (2020) Sharp Analysis of Expectation-Maximization for Weakly Identifiable Mixture Models AISTATS. (<a href="https://arxiv.org/abs/1902.00194">paper</a>)</p>
<p>R. Dwivedi, N. Ho, K. Khamaru, M. J. Wainwright, M. I. Jordan and B. Yu (2020) Singularity, Misspecification and the Convergence Rate of EM Annals of Statistics. (<a href="https://arxiv.org/abs/1810.00828">paper</a>)</p>
<p>Y. Chen, R. Dwivedi, M. J. Wainwright and B. Yu (2020) Fast Mixing of Metropolized Hamiltonian Monte Carlo: Benefits of Multi-Step Gradients. JMLR, (<a href="https://www.jmlr.org/papers/volume21/19-441/19-441.pdf">paper</a>) (<a href="https://arxiv.org/abs/1905.12247">arXiv</a>)</p>
</section>
<section id="section-5" class="level2">
<h2 class="anchored" data-anchor-id="section-5">2019</h2>
<p>R. Dwivedi, Y. Chen, M. J. Wainwright and B. Yu (2019) Log-concave Sampling: Metropolis Hastings Algorithms are Fast JMLR. (<a href="http://jmlr.org/papers/v20/19-306.html">paper</a>)</p>
<p>D. Rothenhäusler and B. Yu (2019). Incremental causal effects. (<a href="https://arxiv.org/abs/1907.13258">paper</a>)</p>
</section>
<section id="section-6" class="level2">
<h2 class="anchored" data-anchor-id="section-6">2018</h2>
<p>Y. Chen, R. Dwivedi, M. J. Wainwright and B. Yu (2018) <a href="http://jmlr.org/papers/v19/18-158.html">Fast MCMC Algorithms on Polytopes.</a> JMLR.</p>
<p>Y. Chen, R. Dwivedi, M. J. Wainwright and B. Yu (2020) Vaidya Walk: A Sampling Algorithm Based on Volumetric-Logarithmic Barrier. Allerton Conference 2017. (<a href="https://ieeexplore.ieee.org/abstract/document/8262876/">paper</a>)</p>
<p>W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, and B. Yu* (2019) Definitions, methods, and applications in interpretable machine learning. PNAS, 116 (44) 22071-22080. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2020/iML19-Murdochetal.pdf">paper</a>)</p>
<p>W. J. Murdoch, C. Sign, and B. Yu (2019). Hierarchical interpretations for neural network predictions. ICLR. (<a href="https://openreview.net/pdf?id=SkEqro0ctQ">paper</a>) (<a href="https://github.com/csinva/hierarchical-dnn-interpretations">code</a>)</p>
<p>Y. Wang, S. Wu and B. Yu (2020) Unique Sharp Local Minimum in l1-minimization Complete Dictionary Learning. JMLR. 21(63), pp.&nbsp;1-52. (<a href="https://jmlr.org/papers/volume21/19-169/19-169.pdf">paper</a>) (<a href="https://arxiv.org/abs/1902.08380">arXiv</a>)</p>
<p>Y. Chen, R. Abbasi-Asl, A. Bloniarz, M. Oliver, B. Willmore, J. Gallant<em>, and B. Yu</em> (2018) The DeepTune framework for modeling and characterizing neurons in visual cortex area V4. (<a href="https://www.biorxiv.org/content/10.1101/465534v1">paper</a>)</p>
<p>K. Kumbier, S. Sumanta, J. B. Brown, S. Celniker, and B. Yu* (2018) Refining interaction search through signed iterative Random Forests. (an enhanced version of iRF, PCS related) (<a href="https://arxiv.org/abs/1810.07287">paper</a>) (<a href="https://www.pnas.org/doi/10.1073/pnas.1711236115">iRF</a>)</p>
<p>Y. Chen C. Jin, and B. Yu (2018) Stability and Convergence Trade-off of Iterative Optimization Algorithms. (<a href="https://arxiv.org/abs/1804.01619">paper</a>)</p>
<p>J. Murdoch, P. Liu, and B. Yu (2018) Beyond word importance: contextual decomposition to extract interactions from LSTMs. Proc. ICLR 2018. (<a href="https://arxiv.org/abs/1801.05453">paper</a>) (<a href="https://github.com/csinva/hierarchical-dnn-interpretations">code</a>)</p>
<p>R. Diwivedi, Y. Chen, M. J. Wainwright, and B. Yu (2018) Log-concave sampling: Metropolis-Hastings algorithms are fast! (<a href="https://arxiv.org/abs/1801.02309">paper</a>)</p>
</section>
<section id="section-7" class="level2">
<h2 class="anchored" data-anchor-id="section-7">2017</h2>
<p>Y. Chen, R. Dwivedi, M. J. Wainwright, and B. Yu (2017) Fast MCMC sampling algorithms on polytopes. (<a href="https://arxiv.org/abs/1710.08165">paper</a>)</p>
<p>B. Yu and K. Kumbier (2018) Artificial Intelligence and Statistics. Frontiers of Information Technology and Electronic Engineering. 19(1), 6-9. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2018/AI+Stat18.pdf">paper</a>)</p>
<p>R. Abbasi-Asl and B. Yu (2017) Structural Compression of Convolutional Neural Networks Based on Greedy Filter Pruning. (<a href="https://arxiv.org/abs/1705.07356">paper</a>)</p>
<p>R. Abbasi-Asl and B. Yu (2017) Interpreting Convolutional Neural Networks Through Compression. NIPS 2017. Symposium on Interpretable Machine Learning. (<a href="https://arxiv.org/abs/1711.02329">paper</a>)</p>
<p>S. Kunzel, J. Sekhon, P. Bickel, and B. Yu* (2019) Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning. PNAS. 116 (10) 4156-4165. (<a href="https://www.pnas.org/content/116/10/4156">paper</a>) (<a href="https://arxiv.org/abs/1706.03461">arXiv</a>) (<a href="https://github.com/soerenkuenzel/hte">code</a>)</p>
<p>S. Basu, K. Kumbier, J. B. Brown<em>, and B. Yu</em> (2018) iterative Random Forests to discover predictive and stable high-order interactions PNAS, 115 (8), 1943-1948. (PCS related) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2018/iRF+SI18.pdf">paper</a>) (<a href="https://github.com/Yu-Group/iterative-Random-Forest">code</a>)</p>
<p>S. Balakrishnan, M. Wainwright, B. Yu (2017) Statistical Guarantees for the EM algorithm: from population to sample-based analysis. Annals of Statistics, 45(1), 77 - 120. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2017/EM17.pdf">paper</a>)</p>
<p>R. Barter and B. Yu (2017) Superheat: An R package for creating beautiful and extendable heatmaps for visualizing complex data. JCGS (revised). (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2017/superheat17.pdf">paper</a>) (<a href="https://github.com/rlbarter/superheat">code</a>)</p>
<p>H. Liu and B. Yu (2017) Comments on: High-dimensional simultaneous inference with the bootstrap by Dezeure et al Test. 26: 740-750. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2017/LiuYu-test17.pdf">paper</a>)</p>
<p>C. Carson et al (2016). UC Berkeley Data Science Planning Initiative Faculty Advisory Board (FAB) Report. (<a href="https://www.stat.berkeley.edu/~binyu/ps/FAB2016.pdf">paper</a>) (<a href="https://www.stat.berkeley.edu/~binyu/ps/FAB-Summary2016.pdf">FAB Report Executive Summary</a>)</p>
<p>S. Wu and B. Yu (2018). Local identifiability of l1-minimization dictionary learning: a sufficient and almost necessary condition. JMLR. 18, 1 - 56. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2018/local-iden18.pdf">paper</a>)</p>
</section>
<section id="section-8" class="level2">
<h2 class="anchored" data-anchor-id="section-8">2016</h2>
<p>K. Rohe, T. Qin and B. Yu* (2016). Co-clustering directed graphs to discover asymmetries and directional communities. Proc. National Academy of Sciences (PNAS), 113(45), 12679 - 12684. (<a href="http://www.pnas.org/content/113/45/12679.full.pdf?with-ds=yes">paper</a>)</p>
<p>R. E. Kass, B. S. Caffo, M. Davidian, X. Meng, B. Yu, Nancy Reid* (2016). Ten simple rules for effective statistical practice. PLoS Comput. Biol., 12(6): e1004961. doi:10.1371/journal.pcbi.1004961 (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2016/Ten-Simple-Rules.pdf">paper</a>)</p>
<p>Siqi Wu, Antony Joseph, Ann S. Hammonds, Susan E. Celniker, Bin Yu<em>, and Erwin Frise</em> (2016). Stability-driven nonnegative matrix factorization to interpret spatial gene expression and build local gene networks (with support information). PNAS, pp.&nbsp;4290 - 4295. (PCS related) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2016/staNMF+SI.pdf">paper</a>) (<a href="https://github.com/yu-group/stanmf">code</a>)</p>
<p>A. Bloniarz, C. Wu, B. Yu, A. Talwalkar (2016). Supervised neighborhoods for distributed nonparametric regression. Proc. of AISTATS, Barcelona, Spain. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2016/AISTATS16.pdf">paper</a>)</p>
</section>
<section id="section-9" class="level2">
<h2 class="anchored" data-anchor-id="section-9">2015</h2>
<p>B. Yu (2015). Data wisdom for data science. Operational Database Management Systems (ODBMS.ORG). (<a href="http://www.odbms.org/2015/04/data-wisdom-for-data-science/">paper</a>)</p>
<p>A. Bloniarz, H. Liu, C. Zhang, J. Sekhon, and B. Yu* (2015). Lasso adjustments of treatment effect estimates in randomized experiments. PNAS. 113, 7383 - 7390. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2016/lasso-adj+SI16.pdf">paper</a>)</p>
<p>P. Ma, M. W. Mahoney and B. Yu (2015). A Statistical Perspective on Algorithmic Leveraging. Journal of Machine Learning Research, 16, (2015), 861-911. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2015/MaMahoneyYu2015.pdf">paper</a>)</p>
<p>T. Moon, Y. Wang, Y. Liu, and B. Yu (2015). Evaluation of a MISR-based high-resolution aerosol retrieval method using AERONET DRAGON campaign data. IEEE Transactions on Geoscience and Remote Sensing, 53, 4328-4339. (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7047927">paper</a>)</p>
</section>
<section id="section-10" class="level2">
<h2 class="anchored" data-anchor-id="section-10">2014</h2>
<p>B. Yu (2014). Let us own data science. Institute of Mathematical Statistics (IMS) Presidental Address, ASC-IMS Joint Conference, Sydney, July, 2014. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2014/IMS-pres-address14-yu.pdf">paper</a>) (<a href="https://www.youtube.com/watch?v=92OjsYQJC1U">video</a>) (<a href="http://bulletin.imstat.org/2014/10/ims-presidential-address-let-us-own-data-science/">IMS Bulletin</a>)</p>
<p>G. Schiebinger, M. J. Wainwright and B. Yu (2014). The geometry of kernelized spectral clustering. Annals of Statistics, 43, 819-846. (<a href="http://arxiv.org/pdf/1404.7552v3.pdf">paper</a>)</p>
<p>L. Miratrix, J. Jia, B. Yu, B. Gawalt, L. El Ghaoui, L. Barnesmoore, S. Clavier (2014). Concise comparative summaries (CCS) of large text corpora with a human experiment. Ann. Applied Statist., 8, 499-529. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2014/CCS14.pdf">paper</a>)</p>
<p>Y. Benjamini and B. Yu (2014). The shuttle estimator for explainable variance in fMRI experiments. Annals of Applied Statistics, 7, 2007-2033. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2012/BenjaminiY12.pdf">paper</a>)</p>
<p>D. Bean, P. Bickel, N. El Karoui and B. Yu (2014). Optimal M-estimation in high-dimensional regression. Proceedings of National Academy of Sciences, 110, 1456314568. (<a href="http://www.pnas.org/content/early/2013/08/08/1307845110.full.pdf+html">paper</a>)</p>
<p>N. El Karoui, D. Bean, P. Bickel, C. Lim, and B. Yu (2014). On robust regression with high-dimensional predictors. Proceedings of National Academy of Sciences, 110, 1455714562. (<a href="http://www.pnas.org/content/early/2013/08/15/1307842110.full.pdf+html">paper</a>)</p>
<p>P. Ma, M. W. Mahoney, B. Yu (2014). A Statistical Perspective on Algorithmic Leveraging. Proc. of International Conference on Machine Learning (ICML) (This conference paper contains some of preliminary results of the journal submission Ma et al.&nbsp;(2015)) (<a href="http://arxiv.org/abs/1306.5362">paper</a>)</p>
<p>A. Bloniarz, A. Talwalkar, J. Terhorst, M. Jordan, D. Patterson, B. Yu and Y. Song (2014). Changepoint Analysis for Efficient Variant Calling. Proc. of RECOMB 2014 (to appear). (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2014/Bloniarzetal14.pdf">paper</a>)</p>
<p>Tao Shi (2013), A conversation with Professor Bin Yu International Chinese Statistical Association (ICSA) Bulletin, Vol 25, Issue 2, pp 85-98. (<a href="http://www.yufamily.org/src/ShiTao_AnInterviewWithProfessorBinYu.php?xref=YuFamily_YuBin_interview_cn">paper</a>) (<a href="http://www.statsblogs.com/2013/07/09/a-conversation-with-professor-bin-yu/">Selected Parts in Statblogs</a>)</p>
<p>A. Joseph and B. Yu (2016). The impact of regularization on spectral clustering. Annals of Statistics. 4, 1765 - 1791. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2016/reg-spectral16.pdf">paper</a>)</p>
<p>C. Lim and B. Yu (2016). Estimation Stability with Cross Validation (ESCV) Journal of Computational and Graphical Statistics. 25, 464 - 492. (First paper towards PCS) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2016/ESCV16.pdf">paper</a>)</p>
</section>
<section id="section-11" class="level2">
<h2 class="anchored" data-anchor-id="section-11">2013</h2>
<p>A. S. Hammonds, C. A. Bristow, W. W. Fisher, R. Weiszmann, S. Wu, V. Hartenstein, M. Kellis, B. Yu, E. Frise, and S. E. Celniker (2013). Spatial expression of transcription factors in Drosophila embryonic organ development. Genome Biology, 14(12), R140. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/Hammondsetal13.pdf">paper</a>)</p>
<p>H. Liu and B. Yu (2013). Asymptotic properties of Lasso+mLS and Lasso+Ridge in sparse high-dimensional linear regression. Electron. J. Statist., 7, 312-3169. (<a href="https://www.stat.berkeley.edu/~binyu/ps/LassoOLSBootstrap13.pdf">paper</a>)</p>
<p>J. Mairal and B. Yu (2013). Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows. Journal of Machine Learning Research, 14, 2449-2485. (<a href="http://jmlr.org/papers/v14/mairal13a.html">paper</a>)</p>
<p>Y. Wang, X. Jiang, B. Yu, M. Jiang (2013). A Hierarchical Bayesian Approach for Aerosol Retrieval Using MISR Data. J. American Statistical Association, 108, 483-493. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/WangJiangYuJiang2013.pdf">paper</a>)</p>
<p>Y. He, J. Jia and B. Yu (2013). Reversible MCMC on Markov equivalence classes of sparse directed acyclic graphs. Annals of Statistics, 41(4), 1742-1779. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/rev-MCMC13.pdf">paper</a>)</p>
<p>B. Yu (2013). Stability. Bernoulli, 19 (4), 1484-1500. (Invited paper for the Special Issue commemorating the 300th anniversary of the publication of Jakob Bernoullis Ars Conjectandi in 1712) (Begining of PCS) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/Yu13.pdf">paper</a>)</p>
<p>J. Mairal and B. Yu (2013). Discussion on Grouping Strategies and Thresholding for High Dimensional Linear Models Journal of Statistical Planning and Inference, 143, 1451-1453.</p>
<p>C. Uhler, G. Raskutti, and P. Buhlmann and B. Yu (2013). Geometry of faithfulness assumption in causal inference. Annals of Statistics, 41, 436-463. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/faithfulness13.pdf">paper</a>)</p>
<p>L. Miratrix, J. Sehkon, and B. Yu (2013). Adjusting Treatment Effect Estimates by Post-Stratification in Randomized Experiments. Journal of Royal Statistical Society, Series B, 75 (part 2), 369-396. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/post-stratification13.pdf">paper</a>)</p>
<p>J. Jia, K. Rohe and B. Yu (2013) The Lasso under Poisson-like Heteroscadecity. Statistica Sinica, 23, 99-118. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2013/lasso-poisson13.pdf">paper</a>)</p>
<p>S. Negahban, P. Ravikumar, M. Wainwrigt, and B. Yu (2012) A unified framework for high-dimensional analysis of M-estimators with decomposable regularizers. Statistical Science, 27, 538-557. (<a href="https://www.stat.berkeley.edu/~binyu/ps/unified-797.pdf">paper</a>)</p>
<p>G. Raskutti, M. Wainwrigt, and B. Yu (2012) Minimax-optimal rates for sparse additive models over kernel classes via convex programming. J. Machine Learning Research, 13, 389-427. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2012/RaskuttiWY12.pdf">paper</a>)</p>
<p>J. Mairal and B. Yu (2012). Complexity analysis of the Lasso regularization path. Proc. of International Conference on Machine Learning (ICML). (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/MairalY12.pdf">paper</a>)</p>
</section>
<section id="section-12" class="level2">
<h2 class="anchored" data-anchor-id="section-12">2012</h2>
<p>Yanfeng Gu, Shizhe Wang, Tao Shi, Yinghui Lu, Eugene E. Clothiaux, and Bin Yu (2012). Multiple-kernel learning-based unmixing algorithm for estimation of cloud fractions with MODIS and CLOUDSAT data. Proc. of IEEE International Geoscience and Remote Sensing Symposium (IGRSS). (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/GuWSLCY12.pdf">paper</a>)</p>
</section>
<section id="section-13" class="level2">
<h2 class="anchored" data-anchor-id="section-13">2011</h2>
<p>S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, J. L. Gallant (2011). Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 21(19), 1641-1646. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2011/NishimotoVNBYG11.pdf">paper</a>) (<a href="https://sites.google.com/site/gallantlabucb/publications/nishimoto-et-al-2011">related videos</a>)</p>
<p>P. Ravikumar, M. Wainwright, G. Raskutti, B. Yu (2011). High-dimensional covariance estimation by minimizing l1-penalized log-determinant divergence. Electronic Journal of Statistics, 5, 935-980. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2011/RavikumarWRY11.pdf">paper</a>)</p>
<p>G. Raskutti, M. Wainwright, B. Yu (2011). Minimax rates of estimation for high-dimensional linear regression over lq-balls. IEEE Trans. Inform. Th., 57(10), 6976-6994. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2011/RaskuttiWainwrightYu2011.pdf">paper</a>)</p>
<p>K. Rohe, S. Chatterjee, and B. Yu (2011). Spectral clustering and the high-dimensional Stochastic Block Model. Annals of Statistics, 39 (4), 1878-1915 (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2011/RoheCY11.pdf">paper</a>)</p>
<p>V. Q. Vu, P. Ravikumar, T. Naselaris, K. N. Kay, J. L. Gallant, B. Yu* (2011). Encoding and decoding V1 fMRI responses to natural images with sparse nonparametric models. Annals of Applied Statistics, 5, 1150-1182. (*First senior author as last author in biology tradition) (<a href="http://arxiv.org/pdf/1104.2805.pdf">paper</a>)</p>
<p>S. N. Pakzad, G. Rocha, and B. Yu (2011). Distributed modal identification by regularized auto regressive models. International Journal of Systems Science, 42, 1473-1489.</p>
<p>J. Yousafzai, P. Sollich, Z. Cvetkovic, and B. Yu (2011). Combined Features and Kernel Design for Robust Phoneme Classification Using Support Vector Machines. IEEE Trans. Audio, Speech and Language Processing (to appear). 64. (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5618550">paper</a>)</p>
<p>X. Dai, J. Jia, B. Yu, El Ghaoui (2011) SBA-term: Sparse Bilingual Association for terms. Proc. International Conference on Semantic Computing. (<a href="http://www.eecs.berkeley.edu/~elghaoui/Pubs/icsc2011.pdf">paper</a>)</p>
<p>B. Yu (2011). Asymptotics and Coding Theory: One of the n - 1 Dimensions of Terry. In Selected Works of Terry Speed (ed.&nbsp;S. Duoit), pp.&nbsp;33-36, Springer. (<a href="http://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/Yu11.pdf">paper</a>)</p>
</section>
<section id="section-14" class="level2">
<h2 class="anchored" data-anchor-id="section-14">2010</h2>
<p>B. Yu (2010). Remembering Leo. Annals of Applied Statistics, 4(4), 1657-1659. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2010/Yu10.pdf">paper</a>)</p>
<p>J. Jia, Y. Benjamini, C. Lim, G. Raskutti, B. Yu (2010). Comment on “Envelope models for parsimonious and efficient multivariate linear regression” by R. D. Cook, B. Li, and F. Chiaromonte. Statistica Sinica, 20, 961-967. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2010/JiaBLRY10.pdf">paper</a>)</p>
<p>G. Raskutti, M. Wainwrigt, and B. Yu (2010) Restricted Eigenvalue Properties for Correlated Gaussian Designs. Journal of Machine Learning Research, 11, 2241-2259. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2010/RaskuttiWY10.pdf">paper</a>)</p>
<p>J. Jia and B. Yu (2010). On model selection consistency of elastic net when p &gt;&gt;n.&nbsp;Statistica Sinica, 10, 595-611. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2010/JiaY10.pdf">paper</a>)</p>
<p>P. Buhlmann and B. Yu (2010). Boosting. Wiley Interdisciplinary Reviews: Computational Statistics, 2, 69-74. (<a href="http://onlinelibrary.wiley.com/doi/10.1002/wics.55/abstract">paper</a>)</p>
<p>L. Huang, J. Jia, B. Yu, B. Chun, P. Maniatis, M. Naik (2010). Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression. Proc. NIPS 2010. (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/HuangJYCMN10.pdf">paper</a>)</p>
<p>Y. Han, F. Wu, J. Jia, Y. Zhuang and B. Yu (2010). Multi-task Sparse Discriminant Analysis (MtSDA) with Overlapping Categories. Proc. of The 24th AAAI Conference on Artificial Intelligence, July 11-15, Atlanta, GA. (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/HanWJZY10.pdf">paper</a>)</p>
<p>B. Gawalt, J. Jia, L. Miratrix, L. El Ghaoui, B. Yu, and S. Clavier (2010). Discovering Word Associations in News Media via Feature Selection and Sparse Classification. Proc. 11th ACM SIGMM International Confernece on Multimedia Information Retrieval (MIR). (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/GawaltJMGYC10.pdf">paper</a>)</p>
</section>
<section id="section-15" class="level2">
<h2 class="anchored" data-anchor-id="section-15">2009</h2>
<p>E. Anderes, B. Yu, V. Jovanovic, C. Moroney, M. Garay, A. Braverman, E. Clothiaux (2009) Maximum Likelihood Estimation of Cloud Height from Multi-Angle Satellite Imagery. Annals of Applied Statistics, 3, 902-921 (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2009/AnderesYJMGBC09.pdf">paper</a>)</p>
<p>T. Shi, M. Belkin, and B. Yu, (2009) Data Spectroscopy: Eigenspace of Convolution Operator and Clustering Annals of Statistics, 37 (6B), 3960-3984. (<a href="https://www.stat.berkeley.edu/~binyu/ps/shi.aos09.pdf">paper</a>)</p>
<p>Vincent Q. Vu, Bin Yu, Robert E. Kass (2009) Information In The Non-Stationary Case Neural computation 21, 688-703. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2009/VuYK09.pdf">paper</a>)</p>
<p>N. Meinshausen and B. Yu (2009). Lasso-type recovery of sparse representations for high-dimensional data. Annals of Statistics 37, 246-270. (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2009/MeinshausenY09.pdf">paper</a>)</p>
<p>P. Zhao, G. Rocha, and B. Yu (2009). The composite absolute penalties family for grouped and hierarchical variable selection Annals of Statistics 37, 3468-3497. (An earlier version ‘appeared as Grouped and hierarchical model selection through composite absolute penalties’ by P. Zhao, G. Rocha and B. Yu, Department of Statistics, UC Berkeley, Tech. Rep 703.) (<a href="https://www.stat.berkeley.edu/~binyu/ps/papers2009/ZhaoRY09.pdf">paper</a>)</p>
<p>S. Negahban, P. Ravikumar, M. Wainwright, and B. Yu (2009). A unified framework for high-dimensional analysis of <span class="math inline">\(M\)</span>-estimators with decomposable regularizers Proc. NIPS, 2009. (This conference paper contains preliminary results of the journal submission Negahban et al.&nbsp;2012). (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/NegahbanRWY09.pdf">paper</a>)</p>
<p>G. Raskutti, M. Wainwright, B. Yu (2009) High-dimensional regression under lq-ball sparsity: Optimal rates of convergence. Proc. of Allerton Conference on Communication, Control, and Computing. (This conference paper contains some of preliminary results of the journal submission Ravikumar et al.&nbsp;2011). (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/RaskuttiWY09b.pdf">paper</a>)</p>
<p>G. Raskutti, M. Wainwrigt, and B. Yu (2009) Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness. Proc. NIPS, 2009. (This conference paper contains some of preliminary results of the journal submission Ravikumar et al.&nbsp;2011). (<a href="https://www.stat.berkeley.edu/~binyu/ps/Conferencepapers/RaskuttiWY09a.pdf">paper</a>)</p>
</section>
<section id="section-16" class="level2">
<h2 class="anchored" data-anchor-id="section-16">2008</h2>
<p>T. Shi, B. Yu, E. Clothiaux, and A. Braverman (2008). Daytime Arctic Cloud Detection based on Multi-angle Satellite Data with Case Studies. Journal of American Statistical Association. 103( 482), 584-593. (<a href="https://www.stat.berkeley.edu/~binyu/ps/jasa_resub.pdf">paper</a>)</p>
<p>Peter Buhlmann and Bin Yu (2008) Invited discussion on “Evidence contrary to the statistical view of boosting (D. Mease and A. Wyner)”. Journal of Machine Learning Research 9, 187-194. (<a href="https://www.stat.berkeley.edu/~binyu/ps/Mease08a_with_discussion.pdf">paper with discussion</a>)</p>
<p>P. Ravikumer, V. Vu, B. Yu, T. Naselaris, K. Kay, J. Gallant (2008). Nonparametric sparse hiearchical models describe V1 fMRI responses to natural images In Adavances in Neural Information Processing Systems (NIPS) 21, (2008). (This conference paper contains some preliminary results of journal paper Vu et al.&nbsp;(2011) on encoding models, but also contains an encoding model that is not in Vu et al.&nbsp;(2011). It does not contain decoding results.) (<a href="https://www.stat.berkeley.edu/~binyu/ps/rocha.pseudo.pdf">paper</a>)</p>
<p>P. Ravikumar, G. Raskutti, M. Wainwright, B. Yu (2008) Model selection in Gaussian graphical models: high-dimensional consistency of l1-regularized MLE. In Adavances in Neural Information Processing Systems (NIPS) 21, (2008). (<a href="https://www.stat.berkeley.edu/~binyu/ps/covsel.nips08.pdf">paper</a>)</p>
<p>T. Shi, M. Belkin, and B. Yu (2008). Data spectroscopy: learning mixture models using eigenspaces of convolution operators. Proc. of ICML 2008. (<a href="https://www.stat.berkeley.edu/~binyu/ps/ICML08.pdf">paper</a>)</p>
<p>M. Ager, Z. Cvetkovic, P. Pollich, and B. Yu (2008). Towards Robust Phoneme Classification Augmentation of PLP Models with Acoustic Waveforms. Proceedings of EUSIPCO. (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7080758">paper</a>)</p>
<p>J. Yousafzai, Z. Cvetković, P. Pollich, and B. Yu (2008). Combined PLP-Acoustic Waveform Classification for Robust Phoneme Recognition using Support Vector Machines. Proceedings of EUSIPCO. (<a href="http://www.eurasip.org/Proceedings/Eusipco/Eusipco2008/papers/1569105546.pdf">paper</a>)</p>
</section>
<section id="section-17" class="level2">
<h2 class="anchored" data-anchor-id="section-17">2007</h2>
<p>N. Meinshausen, G. Rocha, and B. Yu (2007). A tale of three cousins: Lasso, L2Boosting, and Danzig Annals of Statistics (invited discussion on Candes and Tao’s Danzig Selector paper) (<a href="https://www.stat.berkeley.edu/~binyu/ps/aos.dis07.pdf">paper</a>)</p>
<p>V. Vu, B. Yu, and R. Kass (2007). Coverage Adjusted Entropy Estimation. Statistics and Medicine, 26(21), 4039-4060. (<a href="https://www.stat.berkeley.edu/~binyu/ps/entropy.sub.pdf">paper</a>)</p>
<p>B. Yu (2007). Embracing Statistical Challenges in the Information Technology Age. Technometrics (special issue on statistics and information technologies). vol.&nbsp;49 (3), 237-248. (<a href="https://www.stat.berkeley.edu/~binyu/ps/embracing.pdf">paper</a>)</p>
<p>X. Jiang, Y. Liu, B. Yu and M. Jiang (2007). Comparison of MISR aerosol optical thickness with AERONET measurements in Beijing metropolitan area. Remote Sensing of Environment (Special Issue on Multi-angle Imaging SpectroRadiometer), vol.&nbsp;107, pp.&nbsp;45-53. (<a href="https://www.stat.berkeley.edu/~binyu/ps/xin.pdf">paper</a>)</p>
<p>T. Shi, E. E. Clothiaux, B. Yu, A. J. Braverman, and G. N. Groff (2007). Detection of Daytime Arctic Clouds using MISR and MODIS Data. Remote Sensing of Environment (Special Issue on Multi-angle Imaging SpectroRadiometer), vol.&nbsp;107, pp.&nbsp;172-184. (<a href="https://www.stat.berkeley.edu/~binyu/ps/misr-modis.pdf">paper</a>)</p>
</section>
<section id="section-18" class="level2">
<h2 class="anchored" data-anchor-id="section-18">2006</h2>
<p>Peng Zhao and Bin Yu (2006). On Model Selection Consistency of Lasso. J. Machine Learning Research, 7 (nov), 2541-2567. (<a href="https://www.stat.berkeley.edu/~binyu/ps/LassoConsi.pdf">paper</a>)</p>
<p>B. Yu (2006). Comments on: Monitoring networked applications with incremental quantile estimation by Chambers et al.&nbsp;Statist. Sci., 21, 483-485. (<a href="http://arxiv.org/pdf/0708.0338.pdf">paper</a>)</p>
<p>B. Yu (2006). Comments on: Regularization in Statistics, by P. J. Bickel and B. Li. Test, vol.&nbsp;15 (2), pages 314-316. (<a href="https://www.stat.berkeley.edu/~binyu/ps/test06.pdf">paper</a>)</p>
<p>P. Buhlmann and B. Yu (2006). Sparse Boosing Journal of Machine Learning Research ( 7 (June), 1001-1024). This is a shortened and more focused version of Buhlmann and Yu “Boosting, Model Selection, Lasso and Nonnegative Garotte” given below. (<a href="https://www.stat.berkeley.edu/~binyu/ps/rev.pdf">paper</a>)</p>
<p>J. Gao, H. Suzuki, and B. Yu (2006). Approximation Lasso Methods for Language Modeling. Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pp.&nbsp;225-232, Sydney. (<a href="https://www.stat.berkeley.edu/~binyu/ps/acl.06.pdf">paper</a>)</p>
</section>
<section id="section-19" class="level2">
<h2 class="anchored" data-anchor-id="section-19">2005</h2>
<p>T. Shi and B. Yu (2005). Binning in Gaussian Kernel Regularization. Statistica Sinica (special issue on machine learning), 16, 541-567. (<a href="https://www.stat.berkeley.edu/~binyu/ps/binning.final.pdf">paper</a>)</p>
<p>G. Liang, N. Taft, and B. Yu (2005). A fast lightweight approach to origin-destination IP traffic estimation using partial measurements. Tech Report 687, Statistics Department, UCB (accepted for Special Issue of IEEE-IT and ACM Networks on data networks, Jan.&nbsp;2006) (<a href="https://www.stat.berkeley.edu/~binyu/ps/pamtram.final.pdf">paper</a>)</p>
<p>Tong Zhang and B. Yu (2005). Boosting with early stopping: convergence and consistency. The Annals of Statistics. Vol. 33, 1538-1579. (<a href="https://www.stat.berkeley.edu/~binyu/ps/zhang.final.ps">paper</a>)</p>
<p>Castro, M. Coates, G. Liang, R. Nowak, and B. Yu (2005) Network tomography: recent developments. Statistical Science, 19, 499-517. (<a href="http://nowak.ece.wisc.edu/StatSci04.pdf">paper</a>)</p>
<p>C. D. Giurcaneanu and B. Yu (2005). Efficient algorithms for discrete universal denoising for channels with memeory. Proceedings of International Symposium on Information Theory, Australia. (Also as Tech. Report 686, Statistics Department, UCB (Proc. ISIT, Sept.&nbsp;2005)) (<a href="https://www.stat.berkeley.edu/~binyu/ps/isit05.pdf">paper</a>)</p>
</section>
<section id="section-20" class="level2">
<h2 class="anchored" data-anchor-id="section-20">2004</h2>
<p>P. Zhao and B. Yu (2004). Stagewise Lasso (old title: Boosted Lasso) Journal of Machine Learning Research, 8, 2701-2726. (An earlier version appeared as Tech. Report #678, Statistics Department, UC Berkeley (December, 2004; revised in April, 2005) (<a href="https://www.stat.berkeley.edu/~binyu/ps/StagewiseLasso.pdf">paper</a>)</p>
<p>D. J. Diner et al (2004). PARAGON: A Systematic, Integrated Approach to Aerosol Observation and Modeling. American Meterological Society, Oct., 1491-1501. (<a href="https://www.stat.berkeley.edu/~binyu/ps/paragon.pdf">paper</a>)</p>
<p>P. Buhlmann and B. Yu (2004). Discussion on three boosting papers by Jiang, Lugosi and Vayatis, and Zhang Annals of Statistics. 32 (1): 96-101. (<a href="https://www.stat.berkeley.edu/~binyu/ps/disc2.ps">paper</a>)</p>
<p>R. Jorsten and B. Yu (2004). Compressing genomic and proteomic array images for statistical analyses. Invited chapter in a book on Genomic signal processing and statistics, edited by E. R. Dougherty, I. Shmulevich, J. Chen, and Z. J. Wang, pp.&nbsp;341 - 366. (<a href="https://www.stat.berkeley.edu/~binyu/ps/sig.chapter.ps">paper</a>)</p>
<p>G. Liang, B. Yu, and N. Taft (2004). Maximum entropy models: convergence rates and application in dynamic system monitoring. International Symposium on Information Theory, Chicago. (<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1365207&amp;sortType%3Dasc_p_Sequence%26filter%3DAND%28p_IS_Number%3A29909%29%26pageNumber%3D4%26rowsPerPage%3D50">paper</a>)</p>
</section>
<section id="section-21" class="level2">
<h2 class="anchored" data-anchor-id="section-21">2003</h2>
<p>R. Castro, M. Coates, G. Liang, R. Nowak, and B. Yu (2003). Internet Tomography: Recent Developments Statistical Science. Vol. 19(3), 499-517. (<a href="https://www.stat.berkeley.edu/~binyu/ps/cny.pdf">paper</a>)</p>
<p>G. Liang and B. Yu (2003). Maximum Pseudo Likelihood Estimation in Network Tomography. IEEE Trans. on Signal Processing (Special Issue on Data Networks). 51(8), 2043-2053 (<a href="https://www.stat.berkeley.edu/~binyu/ps/pseudo-ieee.ps">paper</a>)</p>
<p>Rebecka Jornsten and Bin Yu (2003). Simultaneous Gene Clustering and Subset Selection for Classification via MDL. Bioinformatics. 19(9): 1100-1109. (<a href="https://www.stat.berkeley.edu/~binyu/ps/bioinformatics.ps">paper</a>)</p>
<p>Peter Buhlmann and Bin Yu (2003). Boosting with the L2 Loss: Regression and Classification. J. Amer. Statist. Assoc. 98, 324-340. (<a href="https://www.stat.berkeley.edu/~binyu/ps/boostingl2.ps">paper</a>)</p>
<p>R. Jornsten, W. Wang, B. Yu, and K. Ramchandran (2003). Microarray image compression: SLOCO and the effects of information loss. Signal Processing Journal (Special Issue on Genomic Signal Processing). 83, 859-869. (<a href="https://www.stat.berkeley.edu/~binyu/ps/spj.ps">paper</a>)</p>
<p>G. Liang and B. Yu (2003). Pseudo Likelihood Estimation in Network Tomography. Proceedings of of Infocom, San Francisco. (<a href="http://infocom2003.ieee-infocom.org/papers/51_03.PDF">paper</a>)</p>
</section>
<section id="section-22" class="level2">
<h2 class="anchored" data-anchor-id="section-22">2002</h2>
<p>Peter Buhlmann and Bin Yu (2002). Analyzing Bagging. Annals of Statistics vol.&nbsp;30, 927-961. (<a href="https://www.stat.berkeley.edu/~binyu/ps/bagging.ps">paper</a>)</p>
<p>R. Jornsten, M. Hansen, and B. Yu (2002). Adaptive Minimum Description Length (MDL) criteria with applications to microarray data. In Advances in Minimum Description Length: Theory and Applications, edited by P. Grunwald, I.J. Myung and M.A.&nbsp;Pitt. The MIT Press, pp.&nbsp;295-321.</p>
<p>Mark Hansen and Bin Yu (2002). Minimum Description Length Model Selection Criteria for Generalized Linear Models.{}, IMS Lecture Notes – Monograph Series, Vol. 40. (<a href="https://www.stat.berkeley.edu/~binyu/ps/mdl_glm.ps">paper</a>)</p>
<p>Rebecka Jornsten, and Bin Yu (2002). Multiterminal Estimation: Extensions and a Geometric interpretation. Proceedings of International Symposium on Information Theory (ISIT), June, 2002. (<a href="https://www.stat.berkeley.edu/~binyu/ps/isit02.ps">paper</a>)</p>
<p>Gerald Schuller, Bin Yu, Dawei Huang, and Bern Edler (2002). Perceptual Audio Coding using Pre- and Poster- Filters and Lossless Compression. IEEE Trans. Speech and Audio Processing. Vol. 10 (6), 379-390 (<a href="https://www.stat.berkeley.edu/~binyu/ps/coding.ps">paper</a>)</p>
<p>Mark Coates, Alfred Hero, Robert Nowak, and Bin Yu (2002). Internet Tomography. Signal Processing Magazine. vol.&nbsp;19, No.&nbsp;3 (May issue), 47-65. (<a href="https://www.stat.berkeley.edu/~binyu/ps/spmag.ps">paper</a>)</p>
</section>
<section id="section-23" class="level2">
<h2 class="anchored" data-anchor-id="section-23">2001</h2>
<p>M. Hansen and B. Yu (2001). Model selection and the principle of Minimum Description Length. Journal of American Statistical Association. 96, 746-774. (<a href="https://www.stat.berkeley.edu/~binyu/ps/mdl.ps">paper</a>)</p>
</section>
<section id="section-24" class="level2">
<h2 class="anchored" data-anchor-id="section-24">2000</h2>
<p>Jin Cao, Drew Davis, Scott Vander Wiel and Bin Yu (2000). Time-varying network tomography: router link data. J. Amer. Statist. Assoc. vol.&nbsp;95, 1063-1075. (<a href="https://www.stat.berkeley.edu/~binyu/Site/ps/net.pdf">PDF</a>) (<a href="https://www.stat.berkeley.edu/~binyu/ps/net.ps">paper</a>)</p>
<p>Peter Buhlmann and Bin Yu (2000). Discussion. Additive logistic regression: a statistical view of boosting, by Friedman, J., Hastie, T. and Tibshirani, R. Annals of Statistics. Vol. 28, 377-386 (<a href="https://www.stat.berkeley.edu/~binyu/ps/disc.ps">paper</a>)</p>
<p>Mark Hansen and Bin Yu (2000). Wavelet thresholding via MDL for natural images. IEEE Trans. Inform. Theory (Special Issue on Information Theoretic Imaging). vol.&nbsp;46, 1778-1788. (<a href="https://www.stat.berkeley.edu/~binyu/ps/lmdl.ps">paper</a>)</p>
<p>Jorma Rissanen and Bin Yu (2000). Coding and compression: a happy union of theory and practice. J. Amer. Statist. Assoc. (Year 2000 Commemorative Vignette on Engineering and Physical Sciences). vol.&nbsp;95, 986-988. (<a href="https://www.stat.berkeley.edu/~binyu/ps/vig.ps">paper</a>)</p>
<p>Lei Li and Bin Yu (2000). Iterated logarithm expansions of the pathwise code lengths for exponential families. IEEE Trans. Inform. Theory. vol.&nbsp;46, 2683-2689. (<a href="https://www.stat.berkeley.edu/~binyu/ps/pred.ps">paper</a>)</p>
<p>G. Chang, B. Yu and M. Vetterli (2000). Adaptive wavelet thresholding for image denoising and compression. IEEE Trans. Image Processing, vol.&nbsp;9, 1532-1546. (<a href="https://www.stat.berkeley.edu/~binyu/ps/jMDLQ.ps">paper</a>)</p>
<p>G. Chang, B. Yu and M. Vetterli (2000). Spatially adaptive wavelet thresholding based on context modeling for image denoising. IEEE Trans. Image Processing, vol.&nbsp;9, 1522-1531. (<a href="https://www.stat.berkeley.edu/~binyu/ps/spatThr.ps">paper</a>)</p>
<p>G. Chang, B. Yu and M. Vetterli (2000). Wavelet thresholding for multiple noisy image copies. IEEE Trans. Image Processing, vol.&nbsp;9, 1631-1635. (<a href="https://www.stat.berkeley.edu/~binyu/ps/mt.ps">paper</a>)</p>
</section>
<section id="section-25" class="level2">
<h2 class="anchored" data-anchor-id="section-25">1999</h2>
<p>Y. Yoo, A. Ortega, and B. Yu (1999). Image subband coding using context-based classification and adaptive quantization. IEEE Trans. Image Processing, vol.&nbsp;8, 1702-1215. (<a href="https://www.stat.berkeley.edu/~binyu/ps/yoo.ps">paper</a>)</p>
<p>B. Yu, M. Ostland, P. Gong and R. Pu (1999). Penalized discriminant analysis of in situ hyperspectral data for conifer species recognition. IEEE Trans. Geoscience and Remote Sensing, in press.</p>
</section>
<section id="section-26" class="level2">
<h2 class="anchored" data-anchor-id="section-26">1998</h2>
<p>A. Barron, J. Rissanen, and B. Yu (1998). The Minimum Description Length principle in coding and modeling. (Special Commemorative Issue: Information Theory: 1948-1998) IEEE. Trans. Inform. Th., 44, 2743-2760. Reprinted in Information 50 Years of Discovery, Theory: S. Verdu and S. McLaughlin (eds), IEEE Press , 1999.</p>
<p>B. Yu and P. Mykland (1998). Looking at Markov samplers through cusum path plots: a simple diagnostic idea. Statistics and Computing , 8, 275-286.</p>
<p>P. Gong, R. Pu and B. Yu (1998) Conifer species recognition: effects of data transformation and band width (in Chinese) Journal of Remote Sensing, 2(3), 211-217.</p>
<p>G. Chang, B. Yu and M. Vetterli (1998). Spatially adaptive wavelet thresholding for image denoising. Proceedings of IEEE International Conference on Image Processing, October, Chicago. (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=862630">paper</a>)</p>
<p>S. G. Chang, B. Yu, and M. Vetterli (1998). Image denoising via lossy compression and wavelet thresholding. Proceedings of International Conference on Image Processing. Santa Barbara, California, vol.&nbsp;1, pp.&nbsp;604-607. (<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=647985">paper</a>)</p>
<p>M. Ostland and B. Yu (1997). Exploring quasi Monte Carlo for marginal density approximation. Statistics and Computing, 7, 217-228. (<a href="https://www.stat.berkeley.edu/~binyu/ps/quasiMC.pdf">paper</a>)</p>
<p>P. Gong, R. Pu, and B. Yu (1997). Conifer species recognition with in Situ hyperspectral data. Remote Sensing of Environment, 62, 189-200.</p>
<p>B. Yu and T. P. Speed (1997). Information and the clone mapping of chromosomes. Ann. Statist. 25, 169-185. (<a href="https://www.stat.berkeley.edu/~binyu/ps/clone.pdf">paper</a>)</p>
</section>
<section id="section-27" class="level2">
<h2 class="anchored" data-anchor-id="section-27">1997</h2>
<p>D. Nelson, T. Speed, and B. Yu (1997). The limits of random fingerprinting. Genomics, 40, 1-12.</p>
<p>B. Yu (1997). Assouad, Fano, and Le Cam. Festschrift for Lucien Le Cam . D. Pollard, E. Torgersen, and G. Yang (eds), pp.&nbsp;423-435, Springer-Verlag. (<a href="https://www.stat.berkeley.edu/~binyu/ps/LeCam.pdf">paper</a>)</p>
</section>
<section id="section-28" class="level2">
<h2 class="anchored" data-anchor-id="section-28">1996</h2>
<p>B. Yu (1996). Lower bounds on expected redundancy for nonparametric classes. IEEE Trans. on Information Theory, 42, 272-275.</p>
<p>Y. Yoo, A. Ortega, and B. Yu (1996). Adaptive quantization of image subbands with efficient overhead rate selection. In Proceedings of IEEE International Conference on Image Processing, Lausanne, Switzerland.</p>
<p>B. Yu (1996). A Statistical analysis of adaptive scalar quantization based on quantized past data. In Proceedings of International Symposium on Information Theory and its Applications (ISITA96), Victoria, Canada. (<a href="https://www.stat.berkeley.edu/~binyu/ps/quan.ps">paper</a>)</p>
</section>
<section id="section-29" class="level2">
<h2 class="anchored" data-anchor-id="section-29">1995</h2>
<p>B. Yu (1995). Comment: Extracting more diagnostic information from a single run using cusum path plot. Statist. Sci., 10, 54-58.</p>
<p>J. Rissanen and B. Yu (1995). MDL learning. In Learning and Geometry: Computational Approaches, Progress in Computer Science and Applied Logic, 14, David Kueker and Carl Smith (eds), Birkhäuser, Boston, pp.&nbsp;3-19.</p>
<p>P. Mykland, L. Tierney, and B. Yu (1995). Regeneration in Markov Chain samplers. J. Amer. Statist. Assoc., 90, 233-241.</p>
</section>
<section id="section-30" class="level2">
<h2 class="anchored" data-anchor-id="section-30">1994</h2>
<p>B. Yu (1994). Rates of convergence for empirical processes of stationary mixing sequences. Ann. Probab. 22, 94-116.</p>
<p>M. Arcones and B. Yu (1994). Central limit theorems for empirical and U-processes of stationary mixing sequences. J. Theor. Probab. 7, 47-71.</p>
<p>B. Yu (1994). Lower bound on the expected redundancy for classes of continuous Markov sources. In Statistical Decision Theory and Related Topics V, S. S. Gupta and J. O. Berger (eds), 453-466.</p>
<p>M. Arcones and B. Yu (1994). Limit theorems for empirical processes under dependence. In Proceedings in Chaos expansions, multiple Wiener integrals and their applications. 205-221.</p>
<p>A. R. Barron, Y. Yang and B. Yu (1994). Asymptotically optimal function estimation by minimum complexity criteria. In Proceedings of 1994 International Symposium on Information Theory, pp.&nbsp;38, Trondheim, Norway.</p>
</section>
<section id="section-31" class="level2">
<h2 class="anchored" data-anchor-id="section-31">1993</h2>
<p>B. Yu and T. Speed (1993). A rate of convergence result for a universal D-semifaithful code. IEEE Trans. on Information Theory 39, 8813-820.</p>
<p>B. Yu (1993). Density estimation in the L∞ norm for dependent data with applications to the Gibbs sampler. Ann. Statist. 21, 711-735.</p>
<p>T. Speed and B. Yu (1993). Model selection and prediction: normal regression. J. Inst. Statist. Math. 45, 35-54.</p>
</section>
<section id="section-32" class="level2">
<h2 class="anchored" data-anchor-id="section-32">1992</h2>
<p>J. Rissanen, T. Speed and B. Yu (1992). Density estimation by stochastic complexity. IEEE Trans. on Information Theory, 38, 315-323.</p>
<p>B. Yu and T. Speed (1992) Data compression and histograms. Probability Theory and Related Fields, 92, 195-229.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/binyu\.stat\.berkeley\.edu");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Bin Yu</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>